# 1.数据预处理
## 1.1 原始数据
数据大小：Shape: (1129, 29)

|u_score|count|
|:------|----:|
|0 |   673|
|1  |  295|
|2   |  50|
|3  |  100|
|4   |   3|
|5   |   8|

二值化(后续)
|u_score|count|
|:------|----:|
|0 |  1000|
|1  |  111|

数据类型: 
| bv     | progress   | duration   | view_percent   | view_time   | u_like   | u_coin   | u_fav   | u_score   | title   | view    | dm      | reply   | time    | like    | coin    | fav     | share   | tag    | tid     | up_name   | up_follow   | up_followers   | dm_rate   | reply_rate   | like_rate   | coin_rate   | fav_rate   | share_rate   |
|:-------|:-----------|:-----------|:---------------|:------------|:---------|:---------|:--------|:----------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:-------|:--------|:----------|:------------|:---------------|:----------|:-------------|:------------|:------------|:-----------|:-------------|
| object | int64      | int64      | float64        | int64       | int64    | int64    | int64   | int64     | object  | float64 | float64 | float64 | float64 | float64 | float64 | float64 | float64 | object | float64 | object    | float64     | float64        | float64   | float64      | float64     | float64     | float64    | float64      |

缺失值信息：
![heatmap](pic/heatmap_1720572709.png)

## 1.2 数据清洗
使用`df_origin = df_origin[df_origin['like_rate'] <= 1]`去除缺失值

此时，**描述性统计信息**:

|              |   count |             mean |          min |              max |
|:-------------|--------:|-----------------:|-------------:|-----------------:|
| progress     |    1111 |    118.368       | -1           |   5808           |
| duration     |    1111 |    291.561       |  0           |  14487           |
| view_percent |    1111 |      0.665997    | -0.01        |      1           |
| view_time    |    1111 |      1.71881e+09 |  1.71764e+09 |      1.72044e+09 |
| u_like       |    1111 |      0.356436    |  0           |      1           |
| u_coin       |    1111 |      0.0225023   |  0           |      2           |
| u_fav        |    1111 |      0.143114    |  0           |      1           |
| u_score      |    1111 |      0.665167    |  0           |      5           |
| view         |    1111 | 509316           | 33           |      3.4398e+07  |
| dm           |    1111 |   1906.2         |  0           | 634543           |
| reply        |    1111 |    935.847       |  0           |  60148           |
| time         |    1111 |      1.7167e+08  |  0           |      1.8554e+08  |
| like         |    1111 |  30181.7         |  2           |      1.87187e+06 |
| coin         |    1111 |   8991.33        |  0           |      1.3686e+06  |
| fav          |    1111 |  14356           |  0           |      1.77907e+06 |
| share        |    1111 |   3217.01        |  0           | 424879           |
| tid          |    1111 |    140.875       | 17           |    267           |
| up_follow    |    1111 |      0.0459046   |  0           |      1           |
| up_followers |    1111 | 280266           |  3           |      1.99079e+07 |
| dm_rate      |    1111 |      0.00206506  |  0           |      0.0882353   |
| reply_rate   |    1111 |      0.00392554  |  0           |      0.212121    |
| like_rate    |    1111 |      0.0849119   |  0.00170971  |      0.703929    |
| coin_rate    |    1111 |      0.00996029  |  0           |      0.145718    |
| fav_rate     |    1111 |      0.0391487   |  0           |      0.237283    |
| share_rate   |    1111 |      0.00513278  |  0           |      0.0342951   |


数据大小：Shape: (1111, 29)

# 2.数据分析
## 2.1 线性回归
线性回归权重(很多特征的权重为0)：

|    | feature      |       weight |
|---:|:-------------|-------------:|
|  0 | bias         |  0.346996    |
|  1 | view_percent |  0.183598    |
|  2 | view         | -6.65674e-08 |
|  3 | dm           | -6.49999e-06 |
|  4 | reply        |  1.22816e-05 |
|  5 | time         | -2.52051e-09 |
|  6 | like         |  1.48664e-06 |
|  7 | coin         | -4.20712e-06 |
|  8 | fav          |  4.43206e-06 |
|  9 | share        | -1.46168e-06 |
| 10 | tid          |  0.00108179  |
| 11 | up_follow    |  0.592448    |
| 12 | up_followers | -1.60063e-08 |
| 13 | dm_rate      |  2.39709     |
| 14 | reply_rate   | -7.13398     |
| 15 | like_rate    |  1.58569     |
| 16 | coin_rate    | 12.7747      |
| 17 | fav_rate     |  5.27233     |
| 18 | share_rate   | -4.46474     |

根据VIF，可以发现存在多重共线性：
|    | feature      |      VIF |
|---:|:-------------|---------:|
|  0 | const        | 82.6104  |
|  1 | view_percent |  1.02149 |
|  2 | view         |  8.13256 |
|  3 | dm           |  5.50464 |
|  4 | reply        |  3.84872 |
|  5 | time         |  1.29561 |
|  6 | like         | 12.4324  |
|  7 | coin         | 12.3259  |
|  8 | fav          | 17.3318  |
|  9 | share        | 16.911   |
| 10 | tid          |  1.05048 |
| 11 | up_follow    |  1.10765 |
| 12 | up_followers |  1.72719 |
| 13 | dm_rate      |  1.32074 |
| 14 | reply_rate   |  1.24017 |
| 15 | like_rate    |  1.79048 |
| 16 | coin_rate    |  1.98098 |
| 17 | fav_rate     |  1.9023  |
| 18 | share_rate   |  1.28513 |

因此，可以删除一些特征

# 2.2 随机森林
### 使用全部数据训练，模型RF

$\color{blue} {RandomForestClassifier 训练集准确率: 0.8442844284428442} $

|    | feature      |   importance |
|---:|:-------------|-------------:|
| 15 | coin_rate    |   0.147653   |
| 14 | like_rate    |   0.0911695  |
| 16 | fav_rate     |   0.0842168  |
|  9 | tid          |   0.0691678  |
|  4 | time         |   0.0654919  |
|  0 | view_percent |   0.062991   |
| 11 | up_followers |   0.0620174  |
|  6 | coin         |   0.0548649  |
| 13 | reply_rate   |   0.0506898  |
| 12 | dm_rate      |   0.048572   |
|  7 | fav          |   0.0426975  |
|  3 | reply        |   0.0383122  |
|  5 | like         |   0.0371292  |
|  1 | view         |   0.0365539  |
| 17 | share_rate   |   0.0364194  |
|  2 | dm           |   0.0344598  |
|  8 | share        |   0.0330889  |
| 10 | up_follow    |   0.00450473 |

分类报告：

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.841085 | 0.983384 |   0.906685 |  662        |
| 1            |    0.827839 | 0.782007 |   0.80427  |  289        |
| 2            |    0.894737 | 0.346939 |   0.5      |   49        |
| 3            |    0.977778 | 0.44     |   0.606897 |  100        |
| 4            |    0        | 0        |   0        |    3        |
| 5            |    0        | 0        |   0        |    8        |
| accuracy     |     |  |    |1111|
| macro avg    |    0.59024  | 0.425388 |   0.469642 |1111|
| weighted avg |    0.843982 | 0.844284 |   0.826147 |1111|

混淆矩阵：

|    |   5 |   0 |   1 |   2 |   3 |   4 |
|---:|----:|----:|----:|----:|----:|----:|
|  5 |   0 |   1 |   7 |   0 |   0 |   0 |
|  0 |   0 | 651 |  10 |   0 |   1 |   0 |
|  1 |   0 |  63 | 226 |   0 |   0 |   0 |
|  2 |   0 |  27 |   5 |  17 |   0 |   0 |
|  3 |   0 |  31 |  24 |   1 |  44 |   0 |
|  4 |   0 |   1 |   1 |   1 |   0 |   0 |

### 划分训练集与验证集训练，模型RF

$\color{blue} {RandomForestClassifier 训练集准确率: 0.865990990990991} $

$\color{orange} {划分训练集与验证集训练的随机森林准确率：0.6457399103139013} $

根据上述结果，可以发现，划分训练集与验证集训练的随机森林准确率较低，其原因可能是过拟合了。并且，4, 5两个类别的预测效果较差，基本没有预测出来。因此，可以考虑对数据进行处理，比如合并类别等。

## 2.3 逻辑回归
### 使用feature-important，模型logistic
权重为：

|              |          0 |         1 |          2 |          3 |           4 |           5 |
|:-------------|-----------:|----------:|-----------:|-----------:|------------:|------------:|
| bias         |  3.18749   | 1.00115   |  0.443342  |  0.265068  | -2.64713    | -2.24991    |
| dm_rate      | -0.25323   | 0.29073   | -0.0217938 | -0.0320727 | -0.00453701 |  0.0209036  |
| reply_rate   | -0.0946271 | 0.259922  | -0.0635945 | -0.0812782 | -0.0112763  | -0.00914572 |
| like_rate    | -3.23531   | 1.19061   | -0.12155   |  1.90336   |  0.0351014  |  0.22779    |
| coin_rate    | -1.77365   | 1.01071   |  0.338968  |  0.0998479 |  0.0470328  |  0.27709    |
| fav_rate     | -2.91653   | 0.149678  |  0.826416  |  1.70208   |  0.0395894  |  0.198764   |
| share_rate   | -0.13101   | 0.0077979 |  0.0844128 |  0.0400249 |  0.00126299 | -0.00248868 |
| up_follow    | -1.27926   | 0.210267  | -0.169482  | -0.186623  |  0.615592   |  0.809508   |
| view_percent | -0.255602  | 0.8265    | -0.81705   |  0.2343    | -0.411088   |  0.42294    |

可以看出，事实上up_follow在0, 4, 5类别中的权重较大，这说明up_follow对于这几个类别的预测有较大的影响，也就是其实可能是一个重要的特征。

$\color{blue} {LogisticRegression 训练集准确率: 0.6210621062106211} $

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.629921 | 0.966767 |   0.762813 |  662        |
| 1            |    0.521277 | 0.16955  |   0.255875 |  289        |
| 2            |    0        | 0        |   0        |   49        |
| 3            |    1        | 0.01     |   0.019802 |  100        |
| 4            |    0        | 0        |   0        |    3        |
| 5            |    0        | 0        |   0        |    8        |
| accuracy     |     |  |    |    1111 |
| macro avg    |    0.358533 | 0.191053 |   0.173082 | 1111        |
| weighted avg |    0.600951 | 0.621062 |   0.522871 | 1111        |

|    |   5 |   0 |   1 |   2 |   3 |   4 |
|---:|----:|----:|----:|----:|----:|----:|
|  5 |   0 |   6 |   2 |   0 |   0 |   0 |
|  0 |   0 | 640 |  22 |   0 |   0 |   0 |
|  1 |   0 | 240 |  49 |   0 |   0 |   0 |
|  2 |   0 |  44 |   5 |   0 |   0 |   0 |
|  3 |   0 |  84 |  15 |   0 |   1 |   0 |
|  4 |   0 |   2 |   1 |   0 |   0 |   0 |

![ROC](pic/ROC_1720572721.png)

同样地，逻辑回归也对4, 5的类别预测效果较差。


# 2.4 GBDT
$\color{blue} {GradientBoostingClassifier 训练集准确率: 0.9567956795679567} $

|    | feature      |   importance |
|---:|:-------------|-------------:|
| 15 | coin_rate    |   0.199278   |
|  4 | time         |   0.106041   |
|  9 | tid          |   0.0968324  |
| 14 | like_rate    |   0.0846115  |
|  0 | view_percent |   0.0811983  |
| 16 | fav_rate     |   0.0718445  |
| 11 | up_followers |   0.0714424  |
| 12 | dm_rate      |   0.0467365  |
| 13 | reply_rate   |   0.044958   |
| 17 | share_rate   |   0.0329409  |
|  7 | fav          |   0.0322382  |
|  3 | reply        |   0.0303012  |
|  2 | dm           |   0.0223369  |
|  1 | view         |   0.020906   |
|  5 | like         |   0.0199489  |
|  6 | coin         |   0.0177432  |
|  8 | share        |   0.0157613  |
| 10 | up_follow    |   0.00488032 |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.949202 | 0.987915 |   0.968172 |  662        |
| 1            |    0.95572  | 0.896194 |   0.925    |  289        |
| 2            |    0.979592 | 0.979592 |   0.979592 |   49        |
| 3            |    1        | 0.91     |   0.95288  |  100        |
| 4            |    1        | 1        |   1        |    3        |
| 5            |    1        | 1        |   1        |    8        |
| accuracy     |    0.956796 | 0.956796 |   0.956796 |    0.956796 |
| macro avg    |    0.980752 | 0.962284 |   0.970941 | 1111        |
| weighted avg |    0.957313 | 0.956796 |   0.956384 | 1111        |

|    |   5 |   0 |   1 |   2 |   3 |   4 |
|---:|----:|----:|----:|----:|----:|----:|
|  5 |   8 |   0 |   0 |   0 |   0 |   0 |
|  0 |   0 | 654 |   8 |   0 |   0 |   0 |
|  1 |   0 |  30 | 259 |   0 |   0 |   0 |
|  2 |   0 |   1 |   0 |  48 |   0 |   0 |
|  3 |   0 |   4 |   4 |   1 |  91 |   0 |
|  4 |   0 |   0 |   0 |   0 |   0 |   3 |



### 使用feature-GBDT[:10]，模型GBDT

$\color{blue} {GradientBoostingClassifier 训练集准确率: 0.9441944194419442} $

### 使用feature-important，模型GBDT

$\color{blue} {GradientBoostingClassifier 训练集准确率: 0.8973897389738974} $

### 划分训练集与验证集训练，模型GBDT

$\color{blue} {GradientBoostingClassifier 训练集准确率: 1.0} $

$\color{orange} {划分训练集与验证集训练的gbdt准确率：0.6591928251121076} $

虽然GBDT的准确率较高，但是划分训练集与验证集训练的准确率较低，可能是过拟合了。


# 3. 过拟合处理

## 3.1 类别二值化
首先，推荐系统可以简单地认为要么用户看，要么用户不看，因此可以将u_score二值化，u_score>=3的为1，否则为0
使用：`df_num['u_score'] = df_num['u_score'].apply(lambda x: 1 if x >= 3 else 0)`

## 3.2 RF

### 使用feature-guess，模型RF

$\color{blue} {RandomForestClassifier 训练集准确率: 0.9360936093609361} $

|    | feature      |   importance |
|---:|:-------------|-------------:|
| 16 | fav_rate     |   0.117232   |
|  9 | tid          |   0.101664   |
| 14 | like_rate    |   0.0782392  |
| 15 | coin_rate    |   0.0685942  |
|  4 | time         |   0.0625356  |
| 12 | dm_rate      |   0.055187   |
|  7 | fav          |   0.0540797  |
| 11 | up_followers |   0.0530816  |
|  6 | coin         |   0.0524482  |
| 17 | share_rate   |   0.0502865  |
|  1 | view         |   0.0491506  |
|  5 | like         |   0.0478283  |
| 13 | reply_rate   |   0.0470741  |
|  2 | dm           |   0.0466329  |
|  8 | share        |   0.0378931  |
|  0 | view_percent |   0.0369394  |
|  3 | reply        |   0.0368008  |
| 10 | up_follow    |   0.00433284 |

|              |   precision |   recall |   f1-score |     support |
|:-------------|------------:|---------:|-----------:|------------:|
| 0            |    0.933707 | 1        |   0.965717 | 1000        |
| 1            |    1        | 0.36036  |   0.529801 |  111        |
| accuracy     |    0.936094 | 0.936094 |   0.936094 |    0.936094 |
| macro avg    |    0.966853 | 0.68018  |   0.747759 | 1111        |
| weighted avg |    0.94033  | 0.936094 |   0.922165 | 1111        |

|    |   1 |    0 |
|---:|----:|-----:|
|  1 |  40 |   71 |
|  0 |   0 | 1000 |

### 使用feature-important，模型RF

$\color{blue} {RandomForestClassifier 训练集准确率: 0.9081908190819082} $


|    | feature      |   importance |
|---:|:-------------|-------------:|
|  4 | fav_rate     |    0.221323  |
|  2 | like_rate    |    0.176441  |
|  3 | coin_rate    |    0.151116  |
|  1 | reply_rate   |    0.122992  |
|  0 | dm_rate      |    0.115644  |
|  5 | share_rate   |    0.107772  |
|  7 | view_percent |    0.0904352 |
|  6 | up_follow    |    0.0142767 |

|              |   precision |    recall |   f1-score |     support |
|:-------------|------------:|----------:|-----------:|------------:|
| 0            |    0.907441 | 1         |   0.951475 | 1000        |
| 1            |    1        | 0.0810811 |   0.15     |  111        |
| accuracy     |    0.908191 | 0.908191  |   0.908191 |    0.908191 |
| macro avg    |    0.953721 | 0.540541  |   0.550737 | 1111        |
| weighted avg |    0.916689 | 0.908191  |   0.871399 | 1111        |

|    |   1 |    0 |
|---:|----:|-----:|
|  1 |   9 |  102 |
|  0 |   0 | 1000 |

### 划分训练集与验证集训练，模型RF

$\color{blue} {RandomForestClassifier 训练集准确率: 0.9054054054054054} $

|    | feature      |   importance |
|---:|:-------------|-------------:|
|  4 | fav_rate     |   0.221114   |
|  2 | like_rate    |   0.179413   |
|  3 | coin_rate    |   0.151744   |
|  1 | reply_rate   |   0.121875   |
|  0 | dm_rate      |   0.121626   |
|  5 | share_rate   |   0.100864   |
|  7 | view_percent |   0.0990473  |
|  6 | up_follow    |   0.00431745 |

|              |   precision |   recall |   f1-score |    support |
|:-------------|------------:|---------:|-----------:|-----------:|
| 0            |    0.904    | 1        |   0.94958  | 791        |
| 1            |    1        | 0.134021 |   0.236364 |  97        |
| accuracy     |    0.905405 | 0.905405 |   0.905405 |   0.905405 |
| macro avg    |    0.952    | 0.56701  |   0.592972 | 888        |
| weighted avg |    0.914486 | 0.905405 |   0.871672 | 888        |

|    |   1 |   0 |
|---:|----:|----:|
|  1 |  13 |  84 |
|  0 |   0 | 791 |

$\color{orange} {划分训练集与验证集训练的随机森林准确率：0.9372197309417041} $

## 3.3 GBDT
### 使用feature-important，模型GBDT

$\color{blue} {GradientBoostingClassifier 训练集准确率: 0.9504950495049505} $

|    |   1 |    0 |
|---:|----:|-----:|
|  1 |  56 |   55 |
|  0 |   0 | 1000 |

### 划分训练集与验证集训练，模型GBDT

$\color{blue} {GradientBoostingClassifier 训练集准确率: 0.9527027027027027} $

|    |   1 |   0 |
|---:|----:|----:|
|  1 |  56 |  41 |
|  0 |   1 | 790 |


$\color{orange} {划分训练集与验证集训练的gbdt准确率：0.9147982062780269} $

注意到此模型的准确率较高，但是仍然存在把1类别预测为0类别的情况，因此可以考虑SMOTE等重采样方法。

## 3.4 逻辑回归

### 使用feature-important，模型logistic

逻辑回归权重

|    | feature      |     weight |
|---:|:-------------|-----------:|
|  0 | bias         | -2.7097    |
|  1 | dm_rate      | -0.0141684 |
|  2 | reply_rate   | -0.0933966 |
|  3 | like_rate    |  2.61375   |
|  4 | coin_rate    |  0.457951  |
|  5 | fav_rate     |  2.1687    |
|  6 | share_rate   |  0.0482939 |
|  7 | up_follow    |  0.570963  |
|  8 | view_percent |  0.209062  |

$\color{blue} {LogisticRegression 训练集准确率: 0.9000900090009001} $

|              |   precision |   recall |   f1-score |    support |
|:-------------|------------:|---------:|-----------:|-----------:|
| 0            |    0.90009  |  1       |   0.947418 | 1000       |
| 1            |    0        |  0       |   0        |  111       |
| accuracy     |    0.90009  |  0.90009 |   0.90009  |    0.90009 |
| macro avg    |    0.450045 |  0.5     |   0.473709 | 1111       |
| weighted avg |    0.810162 |  0.90009 |   0.852762 | 1111       |

|    |   1 |    0 |
|---:|----:|-----:|
|  1 |   0 |  111 |
|  0 |   0 | 1000 |

![ROC](pic/ROC_1720572767.png)

逻辑回归存在明显的把1直接当做0的问题，无语了。

# 5. 重采样
## $\color{blue} {使用SMOTE} $

公式 $ x_{\text {new }}=x_{\text {original }}+\lambda \times\left(x_{\text {neighbor }}-x_{\text {original }}\right) $

## 5.1 RF

$\color{blue} {RandomForestClassifier 训练集准确率: 0.9425} $

|    | feature      |   importance |
|---:|:-------------|-------------:|
| 19 | fav_rate     |   0.20533    |
| 18 | coin_rate    |   0.117278   |
| 17 | like_rate    |   0.113523   |
| 14 | up_followers |   0.0791275  |
|  3 | view_time    |   0.0505337  |
|  7 | time         |   0.045502   |
| 12 | tid          |   0.0451426  |
| 10 | fav          |   0.0416585  |
|  9 | coin         |   0.040561   |
| 20 | share_rate   |   0.0329624  |
|  8 | like         |   0.027455   |
| 16 | reply_rate   |   0.0265686  |
|  5 | dm           |   0.0244198  |
|  0 | progress     |   0.0238278  |
|  2 | view_percent |   0.022564   |
|  1 | duration     |   0.0223441  |
| 15 | dm_rate      |   0.021896   |
| 11 | share        |   0.0179403  |
|  6 | reply        |   0.0178818  |
|  4 | view         |   0.0157051  |
| 13 | up_follow    |   0.00777941 |

|              |   precision |   recall |   f1-score |   support |
|:-------------|------------:|---------:|-----------:|----------:|
| 0            |    0.995822 | 0.889303 |   0.939553 |  804      |
| 1            |    0.899093 | 0.996231 |   0.945173 |  796      |
| accuracy     |    0.9425   | 0.9425   |   0.9425   |    0.9425 |
| macro avg    |    0.947457 | 0.942767 |   0.942363 | 1600      |
| weighted avg |    0.947699 | 0.9425   |   0.942349 | 1600      |

|    |   1 |   0 |
|---:|----:|----:|
|  1 | 793 |   3 |
|  0 |  89 | 715 |

$\color{orange} {划分训练集与验证集训练的随机森林准确率：0.9125} $
注意到，将1预测为0的情况变少了。
### 使用feature-important，模型RF

$\color{blue} {RandomForestClassifier 训练集准确率: 0.875} $

|    |   1 |   0 |
|---:|----:|----:|
|  1 | 783 |  13 |
|  0 | 187 | 617 |


$\color{orange} {划分训练集与验证集训练的随机森林准确率：0.8625} $

## 5.2 GBDT

### 使用feature-important，模型GBDT

$\color{blue} {GradientBoostingClassifier 训练集准确率: 0.903125} $

|    |   1 |   0 |
|---:|----:|----:|
|  1 | 770 |  26 |
|  0 | 129 | 675 |

$\color{orange} {划分训练集与验证集训练的gbdt准确率：0.8775} $

## 5.3 逻辑回归

$\color{blue} {LogisticRegression 训练集准确率: 0.64125} $

![ROC](pic/ROC_1720572781.png)

## 5.4 其他
另外还尝试了使用SVM，但是准确率较低。
还试着更改特征为feature-important-after-Smote，但是准确率也较低。

## 5.5 一阶段总括

### 5.5.1 模型选择
#### 特征集1：

['progress', 'duration', 'view_percent', 'view_time', 'view', 'dm', 'reply', 'time', 'like', 'coin', 'fav', 'share', 'tid', 'up_follow', 'up_followers', 'dm_rate', 'reply_rate', 'like_rate', 'coin_rate', 'fav_rate', 'share_rate']

**准确率表**

|               |   origin |   minmax |   zscore |   smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|--------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.90009  | 0.90099  | 0.89649  |  0.646  |        0.909553 |               0.909553 |               0.906504 |
| svc           | 0.90009  | 0.90099  | 0.905491 |  0.5065 |        0.909553 |               0.909553 |               0.913618 |
| random_forest | 1        | 1        | 1        |  1      |        1        |               1        |               1        |
| gbdtC         | 0.968497 | 0.972097 | 0.972097 |  0.9555 |        0.979675 |               0.978659 |               0.978659 |

**F1表(weight)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.854485 | 0.856627 | 0.858722 | 0.639329 |        0.868413 |               0.868413 |               0.870342 |
| svc           | 0.852762 | 0.85495  | 0.86544  | 0.355121 |        0.866471 |               0.866471 |               0.8761   |
| random_forest | 1        | 1        | 1        | 1        |        1        |               1        |               1        |
| gbdtC         | 0.96582  | 0.970046 | 0.970046 | 0.955466 |        0.978501 |               0.977355 |               0.977355 |

**F1表(unweighted)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.482534 | 0.491453 | 0.51258  | 0.639329 |        0.487281 |               0.487281 |               0.506013 |
| svc           | 0.473709 | 0.482862 | 0.526341 | 0.355121 |        0.476317 |               0.476317 |               0.520344 |
| random_forest | 1        | 1        | 1        | 1        |        1        |               1        |               1        |
| gbdtC         | 0.897818 | 0.911216 | 0.911216 | 0.955466 |        0.931184 |               0.927323 |               0.927323 |

#### 特征集2：

['view_percent', 'view', 'dm', 'reply', 'time', 'like', 'coin', 'fav', 'share', 'tid', 'up_follow', 'up_followers', 'dm_rate', 'reply_rate', 'like_rate', 'coin_rate', 'fav_rate', 'share_rate']

**准确率表**

|               |   origin |   minmax |   zscore |   smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|--------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.89919  | 0.89919  | 0.89739  |   0.653 |        0.90752  |               0.909553 |               0.906504 |
| svc           | 0.90009  | 0.90099  | 0.90459  |   0.5   |        0.909553 |               0.909553 |               0.91565  |
| random_forest | 1        | 1        | 1        |   1     |        1        |               1        |               0.998984 |
| gbdtC         | 0.971197 | 0.972097 | 0.971197 |   0.956 |        0.976626 |               0.976626 |               0.976626 |

**F1表(weight)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.85402  | 0.85402  | 0.86065  | 0.646751 |        0.865456 |               0.868413 |               0.871993 |
| svc           | 0.852762 | 0.85495  | 0.863399 | 0.377917 |        0.866471 |               0.866471 |               0.880672 |
| random_forest | 1        | 1        | 1        | 1        |        1        |               1        |               0.998981 |
| gbdtC         | 0.968998 | 0.970046 | 0.968998 | 0.955972 |        0.97504  |               0.97504  |               0.97504  |

**F1表(unweighted)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.482206 | 0.482206 | 0.520424 | 0.646751 |        0.475759 |               0.487281 |               0.515375 |
| svc           | 0.473709 | 0.482862 | 0.517937 | 0.377917 |        0.476317 |               0.476317 |               0.541001 |
| random_forest | 1        | 1        | 1        | 1        |        1        |               1        |               0.996896 |
| gbdtC         | 0.907915 | 0.911216 | 0.907915 | 0.955972 |        0.919463 |               0.919463 |               0.919463 |

#### 特征集3：

['dm_rate', 'reply_rate', 'like_rate', 'coin_rate', 'fav_rate', 'share_rate', 'up_follow', 'view_percent']

**准确率表**

|               |   origin |   minmax |   zscore |   smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|--------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.90009  | 0.89829  | 0.89649  |  0.6845 |        0.909553 |               0.909553 |               0.906504 |
| svc           | 0.90009  | 0.90009  | 0.90459  |  0.722  |        0.909553 |               0.910569 |               0.911585 |
| random_forest | 1        | 1        | 1        |  1      |        1        |               1        |               1        |
| gbdtC         | 0.950495 | 0.950495 | 0.950495 |  0.9105 |        0.960366 |               0.960366 |               0.960366 |

**F1表(weight)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.852762 | 0.853555 | 0.855777 | 0.683902 |        0.866471 |               0.868413 |               0.868621 |
| svc           | 0.852762 | 0.852762 | 0.863399 | 0.721697 |        0.866471 |               0.868943 |               0.87137  |
| random_forest | 1        | 1        | 1        | 1        |        1        |               1        |               1        |
| gbdtC         | 0.943006 | 0.943006 | 0.943006 | 0.910262 |        0.955228 |               0.955228 |               0.955228 |

**F1表(unweighted)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.473709 | 0.48188  | 0.497425 | 0.683902 |        0.476317 |               0.487281 |               0.496261 |
| svc           | 0.473709 | 0.473709 | 0.517937 | 0.721697 |        0.476317 |               0.487682 |               0.498803 |
| random_forest | 1        | 1        | 1        | 1        |        1        |               1        |               1        |
| gbdtC         | 0.821947 | 0.821947 | 0.821947 | 0.910262 |        0.849051 |               0.849051 |               0.849051 |


注意到这是纯训练集的acc，因此可能存在过拟合的情况。
**小结论：**
- 即使使用了smote，logistic与svc的F1(unweighted)依旧很低，查看控制台的输出会发现还是老问题。比如逻辑回归的混淆矩阵是：

|      |  1  |  0   |
|------|-----|------|
|  1   |  510  |  490 |
|  0   |  218  |  782 |

原因可能是数据特征与用户是否观看的关系是比较复杂的，因此可能需要更加能够体现非线性的模型。

- 不同的特征对结果的影响不大

- zscore的效果较好，不过也没比原始数据好多少


下面使用训练集与验证集：

### 5.2 使用训练集和测试集

以下是**测试集**的输出信息

#### 特征集1：

['progress', 'duration', 'view_percent', 'view_time', 'view', 'dm', 'reply', 'time', 'like', 'coin', 'fav', 'share', 'tid', 'up_follow', 'up_followers', 'dm_rate', 'reply_rate', 'like_rate', 'coin_rate', 'fav_rate', 'share_rate']

**准确率表**

|               |   origin |   minmax |   zscore |   smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|--------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.93722  | 0.932735 | 0.932735 |  0.6775 |        0.908629 |               0.908629 |               0.898477 |
| svc           | 0.93722  | 0.93722  | 0.93722  |  0.49   |        0.908629 |               0.908629 |               0.908629 |
| random_forest | 0.941704 | 0.941704 | 0.941704 |  0.9525 |        0.908629 |               0.908629 |               0.913706 |
| gbdtC         | 0.910314 | 0.910314 | 0.910314 |  0.93   |        0.893401 |               0.898477 |               0.898477 |

**F1表(weight)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.906847 | 0.904602 | 0.911836 | 0.676804 |        0.865131 |               0.865131 |               0.86004  |
| svc           | 0.906847 | 0.906847 | 0.906847 | 0.322282 |        0.865131 |               0.865131 |               0.865131 |
| random_forest | 0.917322 | 0.917322 | 0.917322 | 0.952469 |        0.865131 |               0.865131 |               0.877056 |
| gbdtC         | 0.898719 | 0.898719 | 0.898719 | 0.929921 |        0.871538 |               0.874743 |               0.874743 |

**F1表(unweighted)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.483796 | 0.482599 | 0.541341 | 0.677046 |        0.476064 |               0.476064 |               0.473262 |
| svc           | 0.483796 | 0.483796 | 0.483796 | 0.328859 |        0.476064 |               0.476064 |               0.476064 |
| random_forest | 0.551585 | 0.551585 | 0.551585 | 0.952433 |        0.476064 |               0.476064 |               0.529965 |
| gbdtC         | 0.52187  | 0.52187  | 0.52187  | 0.929858 |        0.551545 |               0.556306 |               0.556306 |

#### 特征集2：

['view_percent', 'view', 'dm', 'reply', 'time', 'like', 'coin', 'fav', 'share', 'tid', 'up_follow', 'up_followers', 'dm_rate', 'reply_rate', 'like_rate', 'coin_rate', 'fav_rate', 'share_rate']

**准确率表**

|               |   origin |   minmax |   zscore |   smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|--------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.932735 | 0.93722  | 0.928251 |   0.7   |        0.908629 |               0.908629 |               0.893401 |
| svc           | 0.93722  | 0.93722  | 0.93722  |   0.49  |        0.908629 |               0.908629 |               0.908629 |
| random_forest | 0.93722  | 0.941704 | 0.941704 |   0.935 |        0.908629 |               0.908629 |               0.908629 |
| gbdtC         | 0.914798 | 0.919283 | 0.919283 |   0.93  |        0.888325 |               0.883249 |               0.888325 |

**F1表(weight)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.904602 | 0.906847 | 0.902346 | 0.694476 |        0.865131 |               0.865131 |               0.857473 |
| svc           | 0.906847 | 0.906847 | 0.906847 | 0.322282 |        0.865131 |               0.865131 |               0.865131 |
| random_forest | 0.914553 | 0.923591 | 0.917322 | 0.934966 |        0.865131 |               0.865131 |               0.865131 |
| gbdtC         | 0.9013   | 0.903897 | 0.903897 | 0.929921 |        0.868366 |               0.859304 |               0.868366 |

**F1表(unweighted)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.482599 | 0.483796 | 0.481395 | 0.695238 |        0.476064 |               0.476064 |               0.47185  |
| svc           | 0.483796 | 0.483796 | 0.483796 | 0.328859 |        0.476064 |               0.476064 |               0.476064 |
| random_forest | 0.546221 | 0.602496 | 0.551585 | 0.93492  |        0.476064 |               0.476064 |               0.476064 |
| gbdtC         | 0.525266 | 0.528873 | 0.528873 | 0.929858 |        0.547032 |               0.508835 |               0.547032 |

#### 特征集3：

['dm_rate', 'reply_rate', 'like_rate', 'coin_rate', 'fav_rate', 'share_rate', 'up_follow', 'view_percent']

**准确率表**

|               |   origin |   minmax |   zscore |   smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|--------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.93722  | 0.93722  | 0.928251 |  0.7175 |        0.908629 |               0.908629 |               0.908629 |
| svc           | 0.93722  | 0.93722  | 0.93722  |  0.7475 |        0.908629 |               0.908629 |               0.908629 |
| random_forest | 0.93722  | 0.93722  | 0.932735 |  0.92   |        0.913706 |               0.908629 |               0.908629 |
| gbdtC         | 0.914798 | 0.914798 | 0.914798 |  0.88   |        0.903553 |               0.903553 |               0.903553 |

**F1表(weight)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.906847 | 0.906847 | 0.902346 | 0.716592 |        0.865131 |               0.865131 |               0.865131 |
| svc           | 0.906847 | 0.906847 | 0.906847 | 0.746193 |        0.865131 |               0.865131 |               0.865131 |
| random_forest | 0.914553 | 0.914553 | 0.904602 | 0.91988  |        0.877056 |               0.865131 |               0.865131 |
| gbdtC         | 0.9013   | 0.9013   | 0.9013   | 0.879648 |        0.871047 |               0.871047 |               0.871047 |

**F1表(unweighted)**

|               |   origin |   minmax |   zscore |    smote |   deleteoutlier |   deleteoutlier_minmax |   deleteoutlier_zscore |
|:--------------|---------:|---------:|---------:|---------:|----------------:|-----------------------:|-----------------------:|
| logistic      | 0.483796 | 0.483796 | 0.481395 | 0.716861 |        0.476064 |               0.476064 |               0.476064 |
| svc           | 0.483796 | 0.483796 | 0.483796 | 0.74651  |        0.476064 |               0.476064 |               0.476064 |
| random_forest | 0.546221 | 0.546221 | 0.482599 | 0.919799 |        0.529965 |               0.476064 |               0.476064 |
| gbdtC         | 0.525266 | 0.525266 | 0.525266 | 0.879491 |        0.52215  |               0.52215  |               0.52215  |

显然smote赢，但是smote的做法真的好吗？要确保两点：
- 1.我们提取的这种外部特征能够反应出视频的质量
- 2.视频的质量与用户是否观看有很强的关系
事实上，第一点就很扯淡，因为我们提取的特征是视频的外部特征，而视频的质量是无法通过这些特征来反应的。因此，模型一定不会很准确。第二点也是不一定的，因为用户是否观看视频是一个很复杂的问题，除了视频的内容，还要用户的兴趣等等。因此，我们的模型可能只是在一定程度上反应了用户是否观看视频的情况。

### 5.3 对随机森林使用交叉验证
#### 特征集1：

['progress', 'duration', 'view_percent', 'view_time', 'view', 'dm', 'reply', 'time', 'like', 'coin', 'fav', 'share', 'tid', 'up_follow', 'up_followers', 'dm_rate', 'reply_rate', 'like_rate', 'coin_rate', 'fav_rate', 'share_rate']

**准确率表：**

|           |   df_origin |   df_origin_zscore |   df_origin_smote |
|:----------|------------:|-------------------:|------------------:|
| accuracy  |   0.889653  |          0.888536  |          0.911875 |
| precision |   0.428571  |          0.0333333 |          0.888689 |
| recall    |   0.0410526 |          0.0310526 |          0.953491 |
| f1        |   0.0679987 |          0.0834921 |          0.917426 |
| roc_auc   |   0.795043  |          0.786665  |          0.978046 |

另外两个不列出，各项数据均低于特征1的。

# 6.smote真的好吗？
## 6.1 问题的提出
显然smote算法默认了数据的分布是线性可分的，但是真的可分吗？
## 6.2 问题的解决
将原始数据集划分为两部分，一部分用于训练，一部分用于测试。训练的数据进行smote，但是测试数据不进行smote
**答案**:
```
              precision    recall  f1-score   support

           0       0.96      0.92      0.94       209
           1       0.27      0.43      0.33        14

    accuracy                           0.89       223
   macro avg       0.62      0.68      0.64       223
weighted avg       0.92      0.89      0.90       223

[[193  16]
 [  8   6]]
```
我的评价是：寄。

## 6.3 其他重采样方法
使用test_size=0.4
```
smote:
              precision    recall  f1-score   support

           0       0.92      0.91      0.91       400
           1       0.28      0.33      0.31        45
    accuracy                           0.85       445
   macro avg       0.60      0.62      0.61       445
weighted avg       0.86      0.85      0.85       445
[[362  38]
 [ 30  15]]

 adasyn:
              precision    recall  f1-score   support

           0       0.92      0.88      0.90       400
           1       0.22      0.29      0.25        45
    accuracy                           0.82       445
   macro avg       0.57      0.59      0.57       445
weighted avg       0.85      0.82      0.83       445
[[353  47]
 [ 32  13]]

smoteenn:
              precision    recall  f1-score   support

           0       0.93      0.84      0.88       400
           1       0.22      0.40      0.28        45
    accuracy                           0.79       445
   macro avg       0.57      0.62      0.58       445
weighted avg       0.85      0.79      0.82       445
[[335  65]
 [ 27  18]]

smotetomek：
               precision    recall  f1-score   support

           0       0.93      0.90      0.91       400
           1       0.28      0.36      0.31        45
    accuracy                           0.84       445
   macro avg       0.60      0.63      0.61       445
weighted avg       0.86      0.84      0.85       445
[[358  42]
 [ 29  16]]
```

不过，使用class_weight与集成算法的效果也比不过：
```python
log_reg = LogisticRegression(class_weight={0: 1, 1: 100}, random_state=42, max_iter=10000)
rf = RandomForestClassifier(class_weight={0: 1, 1: 100}, random_state=42)
svc = SVC(class_weight={0: 1, 1: 100}, probability=True, random_state=42, max_iter=10000)

voting_clf = VotingClassifier(estimators=[
    ('lr', log_reg),
    ('rf', rf),
    ('svc', svc)], voting='soft')
voting_clf.fit(X_train, y_train)
y_pred = voting_clf.predict(X_test)
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
```
```
              precision    recall  f1-score   support

           0       0.90      0.98      0.94       400
           1       0.30      0.07      0.11        45
    accuracy                           0.89       445
   macro avg       0.60      0.52      0.53       445
weighted avg       0.84      0.89      0.86       445
[[393   7]
 [ 42   3]]
```
## 6.4 下一步
检查数据的分布，使用t-SNE算法进行降维，然后使用k-means聚类算法进行聚类。
还可以使用PCA算法进行降维，然后使用k-means聚类算法进行聚类。
可能是特征对类别的区分度不高，导致模型难以准确预测少数类。


# 7. 降维
## 7.1 降维
使用PCA与t-SNE算法进行降维，散点图如下：
![PCA](pic/DR.png)
我的评价是，这看起来都不是线性可分的，因此smote算法可能不适用。

# 7.2 聚类
效果不佳，以kmeans为例：
feature_main:
```
Silhouette Score: 0.7657102771308059
Adjusted Rand Index: 0.015698339665107492
Mutual Information Score: 0.0006039907802191657
```
二维：
```
Silhouette Score: 0.5932017608891539
Adjusted Rand Index: 0.1321847249036661
Mutual Information Score: 0.04819729451080404
```
![kmeans](pic/kmeans.png)
# 7.3 下一步
因smote效果有限、集成算法也一般，聚类效果也不佳，因此下一步可以尝试使用神经网络进行训练。

# 8. 神经网络
## 8.1 resnet
使用resnet进行训练，test_size=0.3，效果如下：
```
训练集：
Accuracy: 0.9852
Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.98      0.99       644
           1       0.98      1.00      0.99       644
    accuracy                           0.99      1288
   macro avg       0.99      0.99      0.99      1288
weighted avg       0.99      0.99      0.99      1288
Confusion Matrix:
[[628  16]
 [  3 641]]

测试集：
Accuracy: 0.8802
Classification Report:
              precision    recall  f1-score   support

           0       0.94      0.93      0.93       301
           1       0.40      0.42      0.41        33

    accuracy                           0.88       334
   macro avg       0.67      0.68      0.67       334
weighted avg       0.88      0.88      0.88       334
Confusion Matrix:
[[280  21]
 [ 19  14]]
```

# 9. 关联规则
## 9.1 普通统计
# 标签统计

## u_score统计

|   u_score |   count |
|----------:|--------:|
|         0 |    1000 |
|         1 |     111 |

## up_name统计(>=5)

| up_name             |   count |
|:--------------------|--------:|
| 碧蓝档案资讯站      |      28 |
| 威威字幕君          |      23 |
| 下江コハル_         |      15 |
| 蔚蓝档案            |      13 |
| 小黑的人间观察记录  |      13 |
| 无敌铁金刚Z         |      12 |
| 钻头V会长           |      10 |
| 河伯__              |      10 |
| oldChtholly         |       9 |
| 梵拉-Valar          |       9 |
| 花崎Makura          |       7 |
| 怀孕的伊吹          |       7 |
| 早濑邮箱单推人      |       7 |
| 碧蓝档案情报站      |       7 |
| 小累了-             |       6 |
| 砂狼白子的老公_BA   |       6 |
| virtual小满         |       6 |
| 刀月你好香          |       6 |
| 禾兮子              |       5 |
| 硬件茶谈            |       5 |
| xinchen-official    |       5 |
| Jungle是丛林        |       5 |
| 深度之眼官方账号    |       5 |
| 一丘之raccoon       |       5 |

## tid统计

|   tid |   count |
|------:|--------:|
|   172 |     343 |
|   252 |     122 |
|   231 |      76 |
|    47 |      63 |
|    27 |      55 |
|    21 |      53 |
|    25 |      47 |
|    65 |      45 |
|    17 |      36 |
|   208 |      34 |
|    24 |      20 |
|   138 |      19 |
|   201 |      18 |
|    28 |      16 |
|    95 |      14 |
|   230 |      11 |
|   122 |      11 |
|   121 |      11 |
|    59 |       9 |
|    31 |       8 |
|   162 |       6 |
|   228 |       6 |
|   130 |       6 |
|    26 |       5 |
|   250 |       5 |
|   193 |       5 |
|   265 |       5 |
|   216 |       5 |
|   229 |       4 |
|    30 |       4 |
|   158 |       3 |
|    22 |       3 |
|   257 |       3 |
|   267 |       3 |
|   253 |       3 |
|    20 |       3 |
|   136 |       2 |
|    51 |       2 |
|   256 |       2 |
|   171 |       2 |
|   233 |       2 |
|   238 |       2 |
|   154 |       2 |
|   255 |       2 |
|   209 |       1 |
|   207 |       1 |
|    86 |       1 |
|   242 |       1 |
|   210 |       1 |
|    29 |       1 |
|   200 |       1 |
|   218 |       1 |
|   164 |       1 |
|   203 |       1 |
|    71 |       1 |
|   126 |       1 |
|   199 |       1 |
|   183 |       1 |
|   221 |       1 |

## up_follow统计

|   up_follow |   count |
|------------:|--------:|
|           0 |    1060 |
|           1 |      51 |

## tag统计(>15)

| tag                             |   count |
|:--------------------------------|--------:|
| 蔚蓝档案                        |     518 |
| 碧蓝档案                        |     460 |
| 二次元                          |     148 |
| 必剪创作                        |      96 |
| Cosplay                         |      91 |
| 搞笑                            |      89 |
| 可爱                            |      83 |
| 小鸟游星野                      |      73 |
| BA                              |      72 |
| 星野                            |      55 |
| 中文字幕                        |      50 |
| cos                             |      50 |
| 原神                            |      44 |
| 手机游戏                        |      44 |
| 爱丽丝                          |      41 |
| 动画                            |      41 |
| 蔚蓝档案/碧蓝档案               |      41 |
| 明日方舟                        |      41 |
| 编程                            |      37 |
| 砂狼白子                        |      36 |
| 剧情                            |      35 |
| 人工智能                        |      35 |
| Blue Archive                    |      34 |
| 明日方舟创作者应援计划          |      33 |
| 娱乐                            |      33 |
| 游戏                            |      32 |
| AI                              |      31 |
| 整活                            |      30 |
| ba                              |      30 |
| 明日方舟UP主应援计划 – 生路     |      29 |
| 白洲梓                          |      26 |
| 原神UP主激励计划                |      25 |
| 白子                            |      24 |
| 沙雕                            |      24 |
| 二创                            |      24 |
| 机器学习                        |      23 |
| sensei                          |      23 |
| 蔚蓝档案二创                    |      22 |
| MMD                             |      22 |
| 优香                            |      22 |
| 计算机                          |      20 |
| 蔚蓝档案公测激励计划            |      20 |
| 主线                            |      19 |
| cosplay                         |      19 |
| 科技猎手                        |      19 |
| 总力战                          |      19 |
| 仿妆cos大神征集令               |      19 |
| 4K                              |      19 |
| 抽象                            |      18 |
| 泳装                            |      18 |
| 深度学习                        |      18 |
| 程序员                          |      18 |
| 科技                            |      18 |
| 学习                            |      17 |
| 蔚蓝档案公测征集                |      17 |
| 日奈                            |      17 |
| 未花                            |      17 |
| 手游                            |      17 |
| 主线剧情                        |      17 |
| 高考                            |      17 |
| 阿拜多斯                        |      16 |
| 科普                            |      16 |
| 同人                            |      15 |
| 美女                            |      15 |
| 原创                            |      15 |
| 阿罗娜                          |      15 |
| MAD                             |      15 |
| 小桃                            |      15 |
| 下江小春                        |      15 |
| 电脑                            |      15 |


## 9.2 关联规则apriori算法

**lift简略版：**

意外的是up_follow=1的没出现过，而更改到很小的`min_support`后，up_follow=1出现了，主要是`up_follow=1 -> 虚拟主播`和`up_follow=1 -> 蔚蓝档案`。

对于u_score=1而言：
```
蔚蓝档案, tid_252 -> 4.32483
tid_252 ->  4.16741
Cosplay ->  3.0797
二次元 ->  1.96122
蔚蓝档案 ->  1.66817
碧蓝档案 ->  1.35088
```
对于u_score=0而言：
```
明日方舟创作者应援计划 -> 33.6667
明日方舟UP主应援计划-生路 -> 33.5216
明日方舟 -> 20.1046
二次元, tid_252 -> 9.96756
Cosplay -> 9.82517
二次元, Cosplay ->  8.39709
cos ->  8.08
```